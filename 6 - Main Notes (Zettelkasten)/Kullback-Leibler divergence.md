2025-09-16 16:26

### Status: #baby

### Tags: [[machine-learning]]

# What is  Kullback-Leibler divergence?

This metric primarily measures the divergence between two probability distributions often used to compare the distribution of outcomes across different groups. KL Divergence is typically used in broader context of distribution comparisons and might not provide a direct assessment of bias, for example related to demographic attributes.


## Descriptions





# References

https://portal.tutorialsdojo.com/courses/aws-certified-machine-learning-engineer-associate-practice-exams-mla-c01-2025/

https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.html

https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-detect-data-bias.html







