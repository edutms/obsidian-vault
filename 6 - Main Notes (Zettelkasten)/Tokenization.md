2025-07-21 11:19

### Status: #baby

### Tags: [[machine-learning]]

# Tokenization

Character tokenization is a method that breaks down text to it's individual characters, so that ML models can treat the words not as single-units of data, but instead singular characters.

It is useful when we have weird/noisy text and be language agnostic.


ChatGPT is cool! --> ["C", "h", "a", "t", "G", "P", "T", " ", "i", "s", " ", "c", "o", "o", "l", "!"]








# References









